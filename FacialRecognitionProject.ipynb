{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmiliaComputing/Machine-Learning/blob/main/FacialRecognitionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-PXkv-M-AFg"
      },
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WT0Cfa85y3TC",
        "outputId": "8c18023c-e0c8-419e-f774-b46b75081fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 29.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     |████████████████████████████████| 438 kB 44.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageai\n",
            "  Downloading imageai-2.1.6-py3-none-any.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 8.3 MB/s \n",
            "\u001b[?25hCollecting keras-resnet==0.2.0\n",
            "  Downloading keras-resnet-0.2.0.tar.gz (9.3 kB)\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imageai) (4.6.0.66)\n",
            "Collecting matplotlib==3.3.2\n",
            "  Downloading matplotlib-3.3.2-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 31.5 MB/s \n",
            "\u001b[?25hCollecting keras==2.4.3\n",
            "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 40.1 MB/s \n",
            "\u001b[?25hCollecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting pillow==7.0.0\n",
            "  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 45.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->imageai) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->imageai) (6.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2022.9.24)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.2->imageai) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib==3.3.2->imageai) (4.1.1)\n",
            "Building wheels for collected packages: keras-resnet\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.2.0-py2.py3-none-any.whl size=20488 sha256=679af6eba552a53814395b99cb82d1a97f6ba395682d667e29a0a3ec375be508\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/ef/06/5d65f696360436c3a423020c4b7fd8c558c09ef264a0e6c575\n",
            "Successfully built keras-resnet\n",
            "Installing collected packages: numpy, scipy, h5py, pillow, keras, matplotlib, keras-resnet, imageai\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.10.0\n",
            "    Uninstalling keras-2.10.0:\n",
            "      Successfully uninstalled keras-2.10.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n",
            "tensorflow 2.10.0 requires keras<2.11,>=2.10.0, but you have keras 2.4.3 which is incompatible.\n",
            "tensorflow 2.10.0 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 imageai-2.1.6 keras-2.4.3 keras-resnet-0.2.0 matplotlib-3.3.2 numpy-1.19.3 pillow-7.0.0 scipy-1.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.10.0\n",
            "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.10.0 requires numpy>=1.20, but you have numpy 1.19.3 which is incompatible.\n",
            "imageai 2.1.6 requires keras==2.4.3, but you have keras 2.10.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.3)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 9.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.3\n",
            "    Uninstalling numpy-1.19.3:\n",
            "      Successfully uninstalled numpy-1.19.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.22+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.23 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "imageai 2.1.6 requires keras==2.4.3, but you have keras 2.10.0 which is incompatible.\n",
            "imageai 2.1.6 requires numpy==1.19.3, but you have numpy 1.21.6 which is incompatible.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install tensorflow --upgrade\n",
        "!pip install imageai --upgrade\n",
        "!pip install keras==2.10.0\n",
        "!pip install numpy --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfxugwne-FyA"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PjnAgPwj1m_e"
      },
      "outputs": [],
      "source": [
        "import imageai\n",
        "import numpy\n",
        "import tensorflow\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "551UfIMO-LTJ"
      },
      "source": [
        "# The dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "h_XUrHFi8nO0",
        "outputId": "5612ba34-4a91-4dd9-ad40-2359ba9a9933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     id                img  name emotion direction_looking eyes_open_closed  \\\n",
              "0  img1       Unknown.jpeg  img1   happy           towards             open   \n",
              "1  img2  Unknown_copy.jpeg  img2   happy           towards             open   \n",
              "2  img3        images.jpeg  img3     sad         away from             open   \n",
              "3  img4   images_copy.jpeg  img4  scared           towards             open   \n",
              "4  img5     smilemask.jpeg  img5   happy           towards             open   \n",
              "\n",
              "  face_covering  \n",
              "0            no  \n",
              "1            no  \n",
              "2            no  \n",
              "3            no  \n",
              "4           yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8163d24d-93f7-46b7-b60b-87f0dcdee018\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "      <th>direction_looking</th>\n",
              "      <th>eyes_open_closed</th>\n",
              "      <th>face_covering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>img1</td>\n",
              "      <td>Unknown.jpeg</td>\n",
              "      <td>img1</td>\n",
              "      <td>happy</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>img2</td>\n",
              "      <td>Unknown_copy.jpeg</td>\n",
              "      <td>img2</td>\n",
              "      <td>happy</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>img3</td>\n",
              "      <td>images.jpeg</td>\n",
              "      <td>img3</td>\n",
              "      <td>sad</td>\n",
              "      <td>away from</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>img4</td>\n",
              "      <td>images_copy.jpeg</td>\n",
              "      <td>img4</td>\n",
              "      <td>scared</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>img5</td>\n",
              "      <td>smilemask.jpeg</td>\n",
              "      <td>img5</td>\n",
              "      <td>happy</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8163d24d-93f7-46b7-b60b-87f0dcdee018')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8163d24d-93f7-46b7-b60b-87f0dcdee018 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8163d24d-93f7-46b7-b60b-87f0dcdee018');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "file = pd.read_csv(\"/content/Emotions/train/emotions.csv\")\n",
        "file.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "eb1eQWi1869s",
        "outputId": "05753265-991a-465c-f032-26b506f9f260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                   img   name emotion direction_looking  \\\n",
              "60  img61          annoyed.jpeg  img61   angry           towards   \n",
              "61  img62       angerwoman.jpeg  img62   angry           towards   \n",
              "62  img63       angrywoman.jpeg  img63   angry           towards   \n",
              "63  img64  angerclosedeyes.jpeg  img64   angry           towards   \n",
              "64  img65          anger._.jpeg  img65   angry           towards   \n",
              "\n",
              "   eyes_open_closed face_covering  \n",
              "60             open           yes  \n",
              "61             open            no  \n",
              "62             open            no  \n",
              "63           closed            no  \n",
              "64             open            no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a3bd94e-994d-4a72-8601-afab08240d20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "      <th>direction_looking</th>\n",
              "      <th>eyes_open_closed</th>\n",
              "      <th>face_covering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>img61</td>\n",
              "      <td>annoyed.jpeg</td>\n",
              "      <td>img61</td>\n",
              "      <td>angry</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>img62</td>\n",
              "      <td>angerwoman.jpeg</td>\n",
              "      <td>img62</td>\n",
              "      <td>angry</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>img63</td>\n",
              "      <td>angrywoman.jpeg</td>\n",
              "      <td>img63</td>\n",
              "      <td>angry</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>img64</td>\n",
              "      <td>angerclosedeyes.jpeg</td>\n",
              "      <td>img64</td>\n",
              "      <td>angry</td>\n",
              "      <td>towards</td>\n",
              "      <td>closed</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>img65</td>\n",
              "      <td>anger._.jpeg</td>\n",
              "      <td>img65</td>\n",
              "      <td>angry</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a3bd94e-994d-4a72-8601-afab08240d20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a3bd94e-994d-4a72-8601-afab08240d20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a3bd94e-994d-4a72-8601-afab08240d20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "file.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "c4R1dub189Sr",
        "outputId": "27f933e8-bc63-4108-bc44-f38cc95282c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id           img  name emotion direction_looking eyes_open_closed  \\\n",
              "count     65            65    65      65                65               65   \n",
              "unique    65            65    62       8                 2                2   \n",
              "top     img1  Unknown.jpeg  img8   happy           towards             open   \n",
              "freq       1             1     3      16                39               49   \n",
              "\n",
              "       face_covering  \n",
              "count             65  \n",
              "unique             2  \n",
              "top               no  \n",
              "freq              48  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7f3c6973-5624-4562-8346-ed102fa43254\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>img</th>\n",
              "      <th>name</th>\n",
              "      <th>emotion</th>\n",
              "      <th>direction_looking</th>\n",
              "      <th>eyes_open_closed</th>\n",
              "      <th>face_covering</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>65</td>\n",
              "      <td>65</td>\n",
              "      <td>62</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>img1</td>\n",
              "      <td>Unknown.jpeg</td>\n",
              "      <td>img8</td>\n",
              "      <td>happy</td>\n",
              "      <td>towards</td>\n",
              "      <td>open</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>39</td>\n",
              "      <td>49</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7f3c6973-5624-4562-8346-ed102fa43254')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7f3c6973-5624-4562-8346-ed102fa43254 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7f3c6973-5624-4562-8346-ed102fa43254');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "file.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXnE0_A6-ReM"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y11TMjc31xu-",
        "outputId": "72a03a6c-7e69-476f-f6f7-6e0f734f593c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Enhanced Data Generation\n",
            "Found 65 images belonging to 9 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "JSON Mapping for the model classes saved to  Emotions/json/model_class.json\n",
            "Number of experiments (Epochs) :  25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/imageai/Classification/Custom/__init__.py:395: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  validation_steps=int(num_test / batch_size), callbacks=[checkpoint, lr_scheduler])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.5570 - accuracy: 0.1406 \n",
            "Epoch 1: accuracy improved from -inf to 0.14062, saving model to Emotions/models/model_ex-001_acc-0.140625.h5\n",
            "2/2 [==============================] - 55s 23s/step - loss: 3.5570 - accuracy: 0.1406 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.5438 - accuracy: 0.1094 \n",
            "Epoch 2: accuracy did not improve from 0.14062\n",
            "2/2 [==============================] - 46s 21s/step - loss: 6.5438 - accuracy: 0.1094 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.5424 - accuracy: 0.2344 \n",
            "Epoch 3: accuracy improved from 0.14062 to 0.23438, saving model to Emotions/models/model_ex-003_acc-0.234375.h5\n",
            "2/2 [==============================] - 46s 24s/step - loss: 3.5424 - accuracy: 0.2344 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.7538 - accuracy: 0.3281 \n",
            "Epoch 4: accuracy improved from 0.23438 to 0.32812, saving model to Emotions/models/model_ex-004_acc-0.328125.h5\n",
            "2/2 [==============================] - 46s 21s/step - loss: 1.7538 - accuracy: 0.3281 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.5621 - accuracy: 0.4242 \n",
            "Epoch 5: accuracy improved from 0.32812 to 0.42424, saving model to Emotions/models/model_ex-005_acc-0.424242.h5\n",
            "2/2 [==============================] - 26s 2s/step - loss: 1.5621 - accuracy: 0.4242 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.7583 - accuracy: 0.3939 \n",
            "Epoch 6: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 22s 1s/step - loss: 1.7583 - accuracy: 0.3939 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.8386 - accuracy: 0.3333    \n",
            "Epoch 7: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 26s 24s/step - loss: 1.8386 - accuracy: 0.3333 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.8595 - accuracy: 0.2812 \n",
            "Epoch 8: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 46s 24s/step - loss: 2.8595 - accuracy: 0.2812 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.6275 - accuracy: 0.3438 \n",
            "Epoch 9: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 49s 21s/step - loss: 1.6275 - accuracy: 0.3438 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.6356 - accuracy: 0.3939    \n",
            "Epoch 10: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 23s 22s/step - loss: 1.6356 - accuracy: 0.3939 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.6294 - accuracy: 0.3438 \n",
            "Epoch 11: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 42s 20s/step - loss: 1.6294 - accuracy: 0.3438 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.2670 - accuracy: 0.3594 \n",
            "Epoch 12: accuracy did not improve from 0.42424\n",
            "2/2 [==============================] - 47s 21s/step - loss: 2.2670 - accuracy: 0.3594 - lr: 1.0000e-04\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.5085 - accuracy: 0.4375 \n",
            "Epoch 13: accuracy improved from 0.42424 to 0.43750, saving model to Emotions/models/model_ex-013_acc-0.437500.h5\n",
            "2/2 [==============================] - 47s 25s/step - loss: 1.5085 - accuracy: 0.4375 - lr: 1.0000e-04\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.8446 - accuracy: 0.5455 \n",
            "Epoch 14: accuracy improved from 0.43750 to 0.54545, saving model to Emotions/models/model_ex-014_acc-0.545455.h5\n",
            "2/2 [==============================] - 23s 2s/step - loss: 1.8446 - accuracy: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.3207 - accuracy: 0.4531 \n",
            "Epoch 15: accuracy did not improve from 0.54545\n",
            "2/2 [==============================] - 46s 21s/step - loss: 1.3207 - accuracy: 0.4531 - lr: 1.0000e-04\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.9743 - accuracy: 0.5152     \n",
            "Epoch 16: accuracy did not improve from 0.54545\n",
            "2/2 [==============================] - 22s 21s/step - loss: 1.9743 - accuracy: 0.5152 - lr: 1.0000e-04\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.5981 - accuracy: 0.5152 \n",
            "Epoch 17: accuracy did not improve from 0.54545\n",
            "2/2 [==============================] - 26s 1s/step - loss: 2.5981 - accuracy: 0.5152 - lr: 1.0000e-05\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.5041 - accuracy: 0.6364 \n",
            "Epoch 18: accuracy improved from 0.54545 to 0.63636, saving model to Emotions/models/model_ex-018_acc-0.636364.h5\n",
            "2/2 [==============================] - 23s 2s/step - loss: 1.5041 - accuracy: 0.6364 - lr: 1.0000e-05\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.7467 - accuracy: 0.5152 \n",
            "Epoch 19: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 25s 2s/step - loss: 1.7467 - accuracy: 0.5152 - lr: 1.0000e-05\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.1929 - accuracy: 0.5781 \n",
            "Epoch 20: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 47s 21s/step - loss: 1.1929 - accuracy: 0.5781 - lr: 1.0000e-05\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.6433 - accuracy: 0.6562 \n",
            "Epoch 21: accuracy improved from 0.63636 to 0.65625, saving model to Emotions/models/model_ex-021_acc-0.656250.h5\n",
            "2/2 [==============================] - 48s 27s/step - loss: 1.6433 - accuracy: 0.6562 - lr: 1.0000e-05\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.7980 - accuracy: 0.5156 \n",
            "Epoch 22: accuracy did not improve from 0.65625\n",
            "2/2 [==============================] - 46s 24s/step - loss: 1.7980 - accuracy: 0.5156 - lr: 1.0000e-06\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.5578 - accuracy: 0.5625 \n",
            "Epoch 23: accuracy did not improve from 0.65625\n",
            "2/2 [==============================] - 45s 24s/step - loss: 1.5578 - accuracy: 0.5625 - lr: 1.0000e-06\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.6606 - accuracy: 0.5156 \n",
            "Epoch 24: accuracy did not improve from 0.65625\n",
            "2/2 [==============================] - 44s 21s/step - loss: 2.6606 - accuracy: 0.5156 - lr: 1.0000e-07\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.5455 \n",
            "Epoch 25: accuracy did not improve from 0.65625\n",
            "2/2 [==============================] - 24s 2s/step - loss: 1.5413 - accuracy: 0.5455 - lr: 1.0000e-07\n"
          ]
        }
      ],
      "source": [
        "from imageai.Classification.Custom import ClassificationModelTrainer\n",
        "\n",
        "model_trainer = ClassificationModelTrainer()\n",
        "model_trainer.setModelTypeAsResNet50()\n",
        "model_trainer.setDataDirectory(r\"Emotions\")\n",
        "model_trainer.trainModel(num_objects=9, num_experiments=25, enhance_data=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MNi24yX-XuN"
      },
      "source": [
        "# Predict the emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nIZBfynUssQY"
      },
      "outputs": [],
      "source": [
        "from imageai.Classification.Custom import CustomImageClassification\n",
        "\n",
        "prediction = CustomImageClassification()\n",
        "\n",
        "prediction.setModelTypeAsResNet50()\n",
        "\n",
        "prediction.setModelPath(\"/content/Emotions/models/model_ex-021_acc-0.656250.h5\")\n",
        "prediction.setJsonPath(\"Emotions/json/model_class.json\")\n",
        "\n",
        "prediction.loadModel(num_objects=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U48SU_GJw2Om",
        "outputId": "85cdb5ad-51e1-4929-b759-dbeeffde0a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter file name: imgtest\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "This image shows a neutral person.\n"
          ]
        }
      ],
      "source": [
        "filename = input(\"enter file name: \")\n",
        "predictions, probabilities = prediction.classifyImage(f\"/content/Emotions/test/{filename}.jpeg\", result_count=9)\n",
        "\n",
        "print(f\"This image shows a {predictions[0].lower()} person.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQq9wFllv1DS"
      },
      "source": [
        "# Train another model\n",
        "\n",
        "To determine which direction a person is looking.\n",
        "\n",
        "If a person's eyes are closed, the direction they are considered to be looking in is towards the camera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jT6BqIWPico",
        "outputId": "6ee4c7e4-1efd-4784-e903-999371cc3dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Enhanced Data Generation\n",
            "Found 65 images belonging to 3 classes.\n",
            "Found 0 images belonging to 0 classes.\n",
            "JSON Mapping for the model classes saved to  direction_looking/json/model_class.json\n",
            "Number of experiments (Epochs) :  25\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.6714 - accuracy: 0.2969 \n",
            "Epoch 1: accuracy improved from -inf to 0.29688, saving model to direction_looking/models/model_ex-001_acc-0.296875.h5\n",
            "2/2 [==============================] - 53s 22s/step - loss: 3.6714 - accuracy: 0.2969 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.9278 - accuracy: 0.5758\n",
            "Epoch 2: accuracy improved from 0.29688 to 0.57576, saving model to direction_looking/models/model_ex-002_acc-0.575758.h5\n",
            "2/2 [==============================] - 26s 25s/step - loss: 2.9278 - accuracy: 0.5758 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.0076 - accuracy: 0.5758\n",
            "Epoch 3: accuracy did not improve from 0.57576\n",
            "2/2 [==============================] - 23s 22s/step - loss: 2.0076 - accuracy: 0.5758 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.2168 - accuracy: 0.3939 \n",
            "Epoch 4: accuracy did not improve from 0.57576\n",
            "2/2 [==============================] - 25s 1s/step - loss: 2.2168 - accuracy: 0.3939 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.2693 - accuracy: 0.6364 \n",
            "Epoch 5: accuracy improved from 0.57576 to 0.63636, saving model to direction_looking/models/model_ex-005_acc-0.636364.h5\n",
            "2/2 [==============================] - 22s 2s/step - loss: 2.2693 - accuracy: 0.6364 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.8920 - accuracy: 0.4848 \n",
            "Epoch 6: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 25s 1s/step - loss: 3.8920 - accuracy: 0.4848 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.1756 - accuracy: 0.4844 \n",
            "Epoch 7: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 49s 24s/step - loss: 1.1756 - accuracy: 0.4844 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.9367 - accuracy: 0.5000 \n",
            "Epoch 8: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 47s 24s/step - loss: 0.9367 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.1521 - accuracy: 0.4545 \n",
            "Epoch 9: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 23s 1s/step - loss: 1.1521 - accuracy: 0.4545 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.0211 - accuracy: 0.5152    \n",
            "Epoch 10: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 23s 21s/step - loss: 1.0211 - accuracy: 0.5152 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.1225 - accuracy: 0.4848\n",
            "Epoch 11: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 30s 28s/step - loss: 2.1225 - accuracy: 0.4848 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.3867 - accuracy: 0.5625 \n",
            "Epoch 12: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 46s 24s/step - loss: 1.3867 - accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.3918 - accuracy: 0.5781 \n",
            "Epoch 13: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 46s 21s/step - loss: 1.3918 - accuracy: 0.5781 - lr: 1.0000e-04\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.9102 - accuracy: 0.6061    \n",
            "Epoch 14: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 22s 21s/step - loss: 0.9102 - accuracy: 0.6061 - lr: 1.0000e-04\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.1336 - accuracy: 0.5455 \n",
            "Epoch 15: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 29s 1s/step - loss: 1.1336 - accuracy: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.2801 - accuracy: 0.6250 \n",
            "Epoch 16: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 46s 23s/step - loss: 1.2801 - accuracy: 0.6250 - lr: 1.0000e-04\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.6364 \n",
            "Epoch 17: accuracy did not improve from 0.63636\n",
            "2/2 [==============================] - 25s 1s/step - loss: 0.6115 - accuracy: 0.6364 - lr: 1.0000e-05\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6917 - accuracy: 0.6667 \n",
            "Epoch 18: accuracy improved from 0.63636 to 0.66667, saving model to direction_looking/models/model_ex-018_acc-0.666667.h5\n",
            "2/2 [==============================] - 24s 2s/step - loss: 0.6917 - accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6734 - accuracy: 0.6250 \n",
            "Epoch 19: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 46s 21s/step - loss: 0.6734 - accuracy: 0.6250 - lr: 1.0000e-05\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7093 - accuracy: 0.6364    \n",
            "Epoch 20: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 24s 22s/step - loss: 0.7093 - accuracy: 0.6364 - lr: 1.0000e-05\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5972 - accuracy: 0.6667\n",
            "Epoch 21: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 25s 24s/step - loss: 0.5972 - accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6346 - accuracy: 0.6562 \n",
            "Epoch 22: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 46s 24s/step - loss: 0.6346 - accuracy: 0.6562 - lr: 1.0000e-06\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6820 - accuracy: 0.6364 \n",
            "Epoch 23: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 23s 1s/step - loss: 0.6820 - accuracy: 0.6364 - lr: 1.0000e-06\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.5758 \n",
            "Epoch 24: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 22s 1s/step - loss: 0.5974 - accuracy: 0.5758 - lr: 1.0000e-07\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7669 - accuracy: 0.5152    \n",
            "Epoch 25: accuracy did not improve from 0.66667\n",
            "2/2 [==============================] - 22s 21s/step - loss: 0.7669 - accuracy: 0.5152 - lr: 1.0000e-07\n"
          ]
        }
      ],
      "source": [
        "model_trainer.setDataDirectory(r\"direction_looking\")\n",
        "model_trainer.trainModel(num_objects=3, num_experiments=25, enhance_data=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmdkpRQrTGK0"
      },
      "source": [
        "# Predict Direction Looking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_bwbcIWMTI2j"
      },
      "outputs": [],
      "source": [
        "predict = CustomImageClassification()\n",
        "\n",
        "predict.setModelTypeAsResNet50()\n",
        "\n",
        "predict.setModelPath(\"/content/direction_looking/models/model_ex-018_acc-0.666667.h5\")\n",
        "predict.setJsonPath(\"direction_looking/json/model_class.json\")\n",
        "\n",
        "predict.loadModel(num_objects=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIFP6GqvUl2J",
        "outputId": "e08b1581-8d65-40d2-ddc2-489999688baf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image you chose earlier was imgtest\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "This image shows a neutral person.\n",
            "They are looking towards the camera.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The image you chose earlier was {filename}\")\n",
        "\n",
        "prediction, probability = predict.classifyImage(f\"/content/direction_looking/test/{filename}.jpeg\", result_count=2)\n",
        "\n",
        "print(f\"This image shows a {predictions[0].lower()} person.\\nThey are looking {prediction[0]} the camera.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viQKOlBjpmFZ"
      },
      "source": [
        "# Train another model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIE_QxgosGoA",
        "outputId": "d8345513-a6b5-4837-9676-4db83b6e5d13"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Enhanced Data Generation\n",
            "Found 65 images belonging to 3 classes.\n",
            "Found 0 images belonging to 1 classes.\n",
            "JSON Mapping for the model classes saved to  eyes_open_closed/json/model_class.json\n",
            "Number of experiments (Epochs) :  25\n",
            "Epoch 1/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.6083 - accuracy: 0.1562     \n",
            "Epoch 1: accuracy improved from -inf to 0.15625, saving model to eyes_open_closed/models/model_ex-001_acc-0.156250.h5\n",
            "2/2 [==============================] - 55s 22s/step - loss: 2.6083 - accuracy: 0.1562 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.0303 - accuracy: 0.6250 \n",
            "Epoch 2: accuracy improved from 0.15625 to 0.62500, saving model to eyes_open_closed/models/model_ex-002_acc-0.625000.h5\n",
            "2/2 [==============================] - 42s 21s/step - loss: 1.0303 - accuracy: 0.6250 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 2.3392 - accuracy: 0.7273\n",
            "Epoch 3: accuracy improved from 0.62500 to 0.72727, saving model to eyes_open_closed/models/model_ex-003_acc-0.727273.h5\n",
            "2/2 [==============================] - 29s 28s/step - loss: 2.3392 - accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.8068 - accuracy: 0.7273 \n",
            "Epoch 4: accuracy did not improve from 0.72727\n",
            "2/2 [==============================] - 25s 1s/step - loss: 0.8068 - accuracy: 0.7273 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 1.6062 - accuracy: 0.5455 \n",
            "Epoch 5: accuracy did not improve from 0.72727\n",
            "2/2 [==============================] - 23s 1s/step - loss: 1.6062 - accuracy: 0.5455 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.6094 \n",
            "Epoch 6: accuracy did not improve from 0.72727\n",
            "2/2 [==============================] - 46s 21s/step - loss: 0.7002 - accuracy: 0.6094 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7917 - accuracy: 0.7500 \n",
            "Epoch 7: accuracy improved from 0.72727 to 0.75000, saving model to eyes_open_closed/models/model_ex-007_acc-0.750000.h5\n",
            "2/2 [==============================] - 56s 26s/step - loss: 0.7917 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4617 - accuracy: 0.8182    \n",
            "Epoch 8: accuracy improved from 0.75000 to 0.81818, saving model to eyes_open_closed/models/model_ex-008_acc-0.818182.h5\n",
            "2/2 [==============================] - 24s 22s/step - loss: 0.4617 - accuracy: 0.8182 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.7812 \n",
            "Epoch 9: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 46s 23s/step - loss: 0.4731 - accuracy: 0.7812 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.7879 \n",
            "Epoch 10: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 24s 1s/step - loss: 0.6676 - accuracy: 0.7879 - lr: 0.0010\n",
            "Epoch 11/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7656 \n",
            "Epoch 11: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 47s 22s/step - loss: 0.4789 - accuracy: 0.7656 - lr: 0.0010\n",
            "Epoch 12/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6558 - accuracy: 0.5625 \n",
            "Epoch 12: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 49s 20s/step - loss: 0.6558 - accuracy: 0.5625 - lr: 1.0000e-04\n",
            "Epoch 13/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.7238 - accuracy: 0.5455\n",
            "Epoch 13: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 27s 25s/step - loss: 0.7238 - accuracy: 0.5455 - lr: 1.0000e-04\n",
            "Epoch 14/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5657 - accuracy: 0.6364 \n",
            "Epoch 14: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 23s 1s/step - loss: 0.5657 - accuracy: 0.6364 - lr: 1.0000e-04\n",
            "Epoch 15/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.6970 \n",
            "Epoch 15: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 26s 1s/step - loss: 0.5766 - accuracy: 0.6970 - lr: 1.0000e-04\n",
            "Epoch 16/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.6970 \n",
            "Epoch 16: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 23s 1s/step - loss: 0.4912 - accuracy: 0.6970 - lr: 1.0000e-04\n",
            "Epoch 17/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5000 - accuracy: 0.7344 \n",
            "Epoch 17: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 46s 21s/step - loss: 0.5000 - accuracy: 0.7344 - lr: 1.0000e-05\n",
            "Epoch 18/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.8182 \n",
            "Epoch 18: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 24s 2s/step - loss: 0.3999 - accuracy: 0.8182 - lr: 1.0000e-05\n",
            "Epoch 19/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.8182 \n",
            "Epoch 19: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 23s 1s/step - loss: 0.4558 - accuracy: 0.8182 - lr: 1.0000e-05\n",
            "Epoch 20/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.6155 - accuracy: 0.6667    \n",
            "Epoch 20: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 22s 21s/step - loss: 0.6155 - accuracy: 0.6667 - lr: 1.0000e-05\n",
            "Epoch 21/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.7273    \n",
            "Epoch 21: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 27s 26s/step - loss: 0.5252 - accuracy: 0.7273 - lr: 1.0000e-05\n",
            "Epoch 22/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.7576\n",
            "Epoch 22: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 30s 28s/step - loss: 0.4568 - accuracy: 0.7576 - lr: 1.0000e-06\n",
            "Epoch 23/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4575 - accuracy: 0.8125 \n",
            "Epoch 23: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 46s 24s/step - loss: 0.4575 - accuracy: 0.8125 - lr: 1.0000e-06\n",
            "Epoch 24/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.8125 \n",
            "Epoch 24: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 47s 22s/step - loss: 0.3992 - accuracy: 0.8125 - lr: 1.0000e-07\n",
            "Epoch 25/25\n",
            "2/2 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.7576    \n",
            "Epoch 25: accuracy did not improve from 0.81818\n",
            "2/2 [==============================] - 25s 24s/step - loss: 0.4688 - accuracy: 0.7576 - lr: 1.0000e-07\n"
          ]
        }
      ],
      "source": [
        "model_trainer.setDataDirectory(r\"eyes_open_closed\")\n",
        "model_trainer.trainModel(num_objects=3, num_experiments=25, enhance_data=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1bDusc5sJnO"
      },
      "source": [
        "# Predict whether the eyes are open or closed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eZTMKH0nsHXu"
      },
      "outputs": [],
      "source": [
        "Predict = CustomImageClassification()\n",
        "\n",
        "Predict.setModelTypeAsResNet50()\n",
        "\n",
        "Predict.setModelPath(\"/content/eyes_open_closed/models/model_ex-008_acc-0.818182.h5\")\n",
        "Predict.setJsonPath(\"/content/eyes_open_closed/json/model_class.json\")\n",
        "\n",
        "Predict.loadModel(num_objects=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSzvRZzsiz3",
        "outputId": "4ed93564-a259-45db-87e9-304160abcb5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The image you chose earlier was imgtest\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "This image shows a neutral person.\n",
            "They are looking towards the camera.\n",
            "They also have open eyes.\n"
          ]
        }
      ],
      "source": [
        "print(f\"The image you chose earlier was {filename}\")\n",
        "Prediction_, Probability_ = predict.classifyImage(f\"/content/eyes_open_closed/test/{filename}.jpeg\", result_count=2)\n",
        "\n",
        "if Prediction_[0] == \"towards\":\n",
        "  Prediction_[0] = \"open\"\n",
        "else:\n",
        "  Prediction_[0] = \"closed\"\n",
        "  \n",
        "print(f\"This image shows a {predictions[0].lower()} person.\\nThey are looking {prediction[0]} the camera.\\nThey also have {Prediction_[0].lower()} eyes.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W-PXkv-M-AFg",
        "Nfxugwne-FyA",
        "551UfIMO-LTJ",
        "fQq9wFllv1DS",
        "SmdkpRQrTGK0",
        "U1bDusc5sJnO"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNbwDMkJLLHC8V/kjpqK+Im",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}